{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic NLP\n",
    "\n",
    "## Natural Language Processing - NLP\n",
    "\n",
    "NLP is processing natual language - free text and speech. We can use free text in predictive modelling, in fact it is a quickly developing field.\n",
    "\n",
    "Technologies such as speech recognition, automatic translation, and computer speech are all based on the concpets that we'll cover here. \n",
    "\n",
    "The premise of NLP is that we take a piece of text and process it to transform into a format that we can process. In our case here we'll take free text and convert it into a set of features - we can then use those features to make predictions for our target, just like always!\n",
    "\n",
    "#### Example Exercise - Spam Filtering\n",
    "\n",
    "For an example we'll build a spam filter. The dataset here has two columns - one is a text message, the other is a human assigned label of spam or ham. We want to be able to detect the spam messages and filter them out. The only feature we have to be able to do so is the message itself..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基礎自然語言處理\n",
    "\n",
    "## 自然語言處理 - NLP\n",
    "\n",
    "NLP 正在處理自然語言——自由文本和語音。 我們可以在預測建模中使用自由文本，事實上這是一個快速發展的領域。\n",
    "\n",
    "語音識別、自動翻譯和計算機語音等技術都基於我們將在此處介紹的概念。\n",
    "\n",
    "NLP的前提是我們拿一段文本，把它處理成我們可以處理的格式。 \n",
    "\n",
    "在我們的例子中，我們將獲取自由文本並將其轉換為一組特徵——然後我們可以使用這些特徵對我們的目標進行預測，就像往常一樣！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "df = pd.read_csv(\"data/spam.csv\", encoding=\"ISO-8859-1\")\n",
    "df.drop(columns={\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"}, inplace=True)\n",
    "df.rename(columns={\"v1\":\"target\", \"v2\":\"text\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵構建\n",
    "\n",
    "與我們習慣的數據不同，我們的自由文本實際上並沒有一組特徵，只有一個特徵包含隨機長度的文本片段。 \n",
    "\n",
    "將隨機文本消息輸入預測算法不太可能有效。 使用自然文本作為我們預測模型的輸入的第一步是將我們的數據轉換為可用的特徵集，我們可以將其輸入模型。 \n",
    "\n",
    "這種轉換將導致我們的一維（某種）自由文本變成（可能）非常高維的特徵集。\n",
    "\n",
    "### 代幣化\n",
    "\n",
    "轉換數據的第一步是從原始文本中提取每個單詞——這個過程稱為分詞。 Tokenizing 獲取句子並將其轉換為 tolkens 列表——句子中的單詞。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Construction\n",
    "\n",
    "Unlike the data that we are used to, our free text doesn't really have a set of features, only one feature that contains random length snipits of text. Feeding in random text messages to a predictive algorithm is unlikely to be effective. The first step in using natural text as an input for our predictive models is to transform our data into a usable feature set that we can feed into a model. This transformation will result in our 1 dimension (kind of) free text turning into a (probably) very high dimension set of features. \n",
    "\n",
    "### Tokenization\n",
    "\n",
    "The first step in transforming the data is to extract each word from the original text - this process is called Tokenizing. Tokenizing takes a sentance and transforms it into a list of tolkens - the words in the sentence. \n",
    "\n",
    "![Tokenization](images/tokenization.png \"Tokenization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very Simple Tokenizer\n",
    "\n",
    " We can visualize the process of tokenization pretty easily by looking at an example of a dead simple tokenizer. The function below will tokenize a sentence in a basic way - it will chop apart the sentence into words, and add them to a list. This example uses regex to do basic filtering to only extract words that are 2+ letters. \n",
    "\n",
    "<b>Note:</b> This example of a tokenizer (and this stuff in general) is a very basic version, and the field of NLP is developing quickly. More advanced text processing is better able to capture more of the structure of the language, and more of the meaning. We are stripping lots of \"hidden\" meaning out to make it manageable, more advanced NLP tries to understand as much of that meaning as possible. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非常簡單的分詞器\n",
    "\n",
    "  我們可以通過查看一個死的簡單分詞器的例子來很容易地形象化分詞的過程。 \n",
    "  \n",
    "  下面的函數將以基本方式對句子進行分詞——它將句子分成單詞，並將它們添加到列表中。 \n",
    "  \n",
    "  此示例使用正則表達式進行基本過濾以僅提取 2 個以上字母的單詞。\n",
    "\n",
    "<b>注意：</b>這個標記器示例（以及一般的這個東西）是一個非常基礎的版本，NLP 領域正在快速發展。 \n",
    "\n",
    "更高級的文本處理能夠更好地捕捉更多的語言結構和更多的含義。 我們正在剝離許多“隱藏”的含義以使其易於管理，更高級的 NLP 會嘗試盡可能多地理解該含義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Really simple tokenizer\n",
    "def tokenize(sentence):\n",
    "    tokens = []\n",
    "    for token in re.findall(r\"\\b\\w\\w+\\b\", sentence):\n",
    "        tokens.append(token.lower())\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize a Thing...\n",
    "\n",
    "We can look at the example of one of our sentences being transformed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\n",
      "['freemsg', 'hey', 'there', 'darling', 'it', 'been', 'week', 'now', 'and', 'no', 'word', 'back', 'like', 'some', 'fun', 'you', 'up', 'for', 'it', 'still', 'tb', 'ok', 'xxx', 'std', 'chgs', 'to', 'send', '50', 'to', 'rcv']\n"
     ]
    }
   ],
   "source": [
    "tolk = tokenize(df[\"text\"][5])\n",
    "print(df[\"text\"][5])\n",
    "print(tolk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Results\n",
    "\n",
    "Tokenizing transforms our random text into something more orderly and able to be processed - in this case a list of words. This tokenization process is the basis of all other processing. \n",
    "\n",
    "We can take this set of tokens and do some further processing. For this we'll use something called a Vectorizer. The vectorizer will do the simple act of tokenizing, and build the actual data structure that we need as a feature set. \n",
    "\n",
    "#### Vocabulary\n",
    "\n",
    "The set of all our tokens, or all words used in our dataset is called the vocabulary. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizers\n",
    "\n",
    "In sklearn we have some libraries called vectorizors - they can do much of the text processing for us. There are two that we'll touch on - CountVectorizer and Tf-idf Vectorizer. \n",
    "\n",
    "Each of these does the bulk of the prep for us:\n",
    "<ul>\n",
    "<li> Tokenize the strings. \n",
    "<li> Count the occurances of each. \n",
    "<li> Weight the relative importance of different words. In different ways...\n",
    "<li> Produce a usable feature set. \n",
    "</ul> \n",
    "\n",
    "<b> Each takes in a dataset of text strings and outputs a set of features that we can use for our predictions. </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorization\n",
    "\n",
    "Count vectorization is the most simple process we can use to make our text into a set of features. The count vectorization will split apart our data into tokens, count them up, and produce an array where:\n",
    "<ul>\n",
    "<li> Each column is a word. \n",
    "<li> Each row is an input piece of text (e.g. an email)\n",
    "<li> Each cell is a count of the number of times that word appears. \n",
    "</ul>\n",
    "\n",
    "![Count Vectorization](images/count_vector.png \"Count Vectorization\")\n",
    "\n",
    "This is our Bag of Words - now instead of having a sentence as an input, we have something like a one-hot matrix of words used. We can picture this by printing it out (Note: there's a little reconstruction below to put it into a nice dataframe format)\n",
    "\n",
    "#### Count Vectorizer Benefits and Drawbacks\n",
    "\n",
    "The main benefit of the count vectorizer is the simplicity and speed - all it needs to do is count. It has the downside of being quite simple in the analysis of the language - we don't extract which words are more or less important, we just get a count. For things that are written similarly this can be effective - I have used this for a simple tool to detect cheaters on tests - people copying from each other or a common source like Chegg tend to have the same words repeated in their answer. \n",
    "\n",
    "#### Sparse Features\n",
    "\n",
    "This process generally produces a sparse matrix - most words are not in most sentences, so most scores in the final matrix are 0. For this we'll keep it simple and use algorithms that deal with sparse matrices (e.g. SVC). Later on we'll look at ways to reduce dimensionality.\n",
    "\n",
    "Some algorithms may throw an error if you feed them a sparse matrix. \n",
    "\n",
    "### Use Count Vectorizer\n",
    "\n",
    "We can look at the dataset that is generated for us after using the count vectorizer. The mechanics are very similar to the other sklearn transformers that we've used. The output is an array, so there's a little extra code there to put it into a dataframe for easy viewing. For the first try I'll set a limit of 150 features, so only the most common 150 tokens will be kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (5572,)\n",
      "vectorized: (5572, 150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elsa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>all</th>\n",
       "      <th>already</th>\n",
       "      <th>am</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>won</th>\n",
       "      <th>work</th>\n",
       "      <th>www</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>ì_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      about  after  all  already  am  amp  an  and  any  are  ...  will  with  \\\n",
       "812       0      0    0        0   0    0   0    0    0    0  ...     0     0   \n",
       "4548      0      0    0        0   0    0   0    0    0    0  ...     0     0   \n",
       "2718      0      0    1        0   0    0   0    1    0    0  ...     1     0   \n",
       "3050      0      0    0        0   0    1   0    0    0    0  ...     0     1   \n",
       "2668      0      0    0        0   0    0   0    0    0    0  ...     0     0   \n",
       "4417      0      0    0        0   0    0   0    0    0    0  ...     0     0   \n",
       "1210      0      0    0        0   0    0   0    0    0    0  ...     0     0   \n",
       "1808      0      0    0        0   1    0   0    0    0    0  ...     0     0   \n",
       "3995      0      0    0        0   0    0   0    0    0    0  ...     0     0   \n",
       "1166      0      0    0        0   1    0   0    0    0    0  ...     0     0   \n",
       "\n",
       "      won  work  www  yeah  yes  you  your  ì_  \n",
       "812     0     0    1     0    0    0     0   0  \n",
       "4548    0     0    0     0    0    1     0   0  \n",
       "2718    0     0    0     0    0    0     0   0  \n",
       "3050    0     0    0     0    0    0     0   0  \n",
       "2668    0     0    0     0    0    0     0   0  \n",
       "4417    0     0    0     0    0    1     0   0  \n",
       "1210    0     0    0     0    0    1     0   0  \n",
       "1808    0     0    0     0    0    0     0   1  \n",
       "3995    0     0    0     0    0    1     0   0  \n",
       "1166    0     0    0     0    0    0     0   0  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_cv = CountVectorizer(max_features=150)\n",
    "tmp = vec_cv.fit_transform(df[\"text\"])\n",
    "tok_cols = vec_cv.get_feature_names()\n",
    "tok_df = pd.DataFrame(tmp.toarray(), columns=tok_cols)\n",
    "print(\"original:\", df[\"text\"].shape)\n",
    "print(\"vectorized:\", tmp.shape)\n",
    "tok_df.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That has the number of features limited to 150, if we imposed no limits we'd get something way messier... If we look at some of the words that we can see in the columns below, we can surmise that we are probably getting a bunch of junk that isn't all that useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (5572,)\n",
      "vectorized: (5572, 8672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elsa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>ó_</th>\n",
       "      <th>û_</th>\n",
       "      <th>û_thanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5445</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "5445   0    0       0             0     0     0            0            0   \n",
       "2329   0    0       0             0     0     0            0            0   \n",
       "3750   0    0       0             0     0     0            0            0   \n",
       "3036   0    0       0             0     0     0            0            0   \n",
       "1382   0    0       0             0     0     0            0            0   \n",
       "1667   0    0       0             0     0     0            0            0   \n",
       "3613   0    0       0             0     0     0            0            0   \n",
       "1120   0    0       0             0     0     0            0            0   \n",
       "5043   0    0       0             0     0     0            0            0   \n",
       "106    0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  ó_  û_  û_thanks  ûªm  ûªt  ûªve  ûï  ûïharry  ûò  \\\n",
       "5445           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "2329           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "3750           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "3036           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "1382           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "1667           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "3613           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "1120           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5043           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "106            0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "\n",
       "      ûówell  \n",
       "5445       0  \n",
       "2329       0  \n",
       "3750       0  \n",
       "3036       0  \n",
       "1382       0  \n",
       "1667       0  \n",
       "3613       0  \n",
       "1120       0  \n",
       "5043       0  \n",
       "106        0  \n",
       "\n",
       "[10 rows x 8672 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_cv2 = CountVectorizer()\n",
    "tmp2 = vec_cv2.fit_transform(df[\"text\"])\n",
    "tok_cols2 = vec_cv2.get_feature_names()\n",
    "tok_df2 = pd.DataFrame(tmp2.toarray(), columns=tok_cols2)\n",
    "print(\"original:\", df[\"text\"].shape)\n",
    "print(\"vectorized:\", tmp2.shape)\n",
    "tok_df2.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectorizer Results\n",
    "\n",
    "Each of the vectorizations above delivered us a fully formed feature set. Each row is one piece of our input text, each column is a word, and each cell is the count of the number of times that word occurs in that text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization\n",
    "\n",
    "TF-IDF vectorization is similar to the count vectorizor, but it does some calculations to determine the importance of the word. The calculations are based on the name:\n",
    "<ul>\n",
    "<li> <b>Term Frequency</b> - the number of times a word appears in a document divided by the total number of words in the document.\n",
    "<li> <b>Inverse Document Frequency</b> - the log of the total number of documents divided by the number of documents that contain the word.\n",
    "<li> <b>Note:</b> each input phrase (row in dataset) is a document. \n",
    "</ul>\n",
    "\n",
    "![TF-IDF](images/tfidf.png \"TF-IDF\" )\n",
    "\n",
    "The final result is the two multiplied by each other, hence TF-IDF. \n",
    "\n",
    "#### TF-IDF Importance\n",
    "\n",
    "TF-IDF weights the importance of each word to give lower scores to words that are:\n",
    "<ul>\n",
    "<li> <b>Too frequent</b> - words that repeat constantly are likely to not be helpful in differentiating sentences. \n",
    "    <ul>\n",
    "    <li> \"the\", \"it\", \"and\", \"to\", \"for\", etc. and other common words occur in a huge proportion of documents, so they are not very useful in differentiating between documents.\n",
    "    <li> In specific applications, other words that are common in that domain may also become too frequent.\n",
    "    </ul>\n",
    "<li> <b>Too rare</b> - words that almost never occur don't exist often enough to establish a pattern. \n",
    "    <ul>\n",
    "    <li> If words only extremely occasionally in our dataset, those rare words are not likely to be useful in differentiating between documents, since we just don't see them enough to establish any sort of pattern.\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "TF-IDF tends to give us a better ability to evaluate work importance, but it is still not able to extract relationships between words nor generate more sophisticated meaning of the words. For that we need to use more sophisticated processing libraries, such as word2vec that we'll look at later on. \n",
    "\n",
    "<b>Note:</b> a small change here in the max features argument, now it'll keep the 150 overall highest scoring tokens. This is slightly differnet from the most frequent, as those words that score poorly in the td-idf calculation will be dropped."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 向量化\n",
    "\n",
    "TF-IDF 向量化類似於計數向量化器，但它會進行一些計算以確定單詞的重要性。 計算基於名稱：\n",
    "<ul>\n",
    "<li> <b>詞頻</b> - 文檔中單詞出現的次數除以文檔中的單詞總數。\n",
    "<li> <b>反向文檔頻率</b> - 文檔總數除以包含該詞的文檔數的對數。\n",
    "<li> <b>注意：</b>每個輸入短語（數據集中的行）都是一個文檔。\n",
    "\n",
    "\n",
    "#### TF-IDF 重要性\n",
    "\n",
    "TF-IDF 對每個詞的重要性進行加權，以對以下詞給予較低的分數：\n",
    "<ul>\n",
    "<li> <b>太頻繁</b> - 不斷重複的單詞可能對區分句子沒有幫助。\n",
    "     <ul>\n",
    "     <li> “the”、“it”、“and”、“to”、“for”等常用詞在文檔中出現的比例很大，因此它們在區分文檔方面作用不大。\n",
    "\n",
    "     <li> 在特定應用中，該領域中常見的其他詞也可能變得過於頻繁。\n",
    "     </ul>\n",
    "<li> <b>Too rare</b> - 幾乎從未出現過的詞的存在頻率不足以建立一種模式。\n",
    "     <ul>\n",
    "     <li> 如果單詞在我們的數據集中出現的頻率非常低，那麼這些不常見的單詞不太可能對區分文檔有用，因為我們對它們的了解不足以建立任何類型的模式。\n",
    "     </ul>\n",
    "</ul>\n",
    "\n",
    "TF-IDF 傾向於給我們更好的評估工作重要性的能力，但它仍然不能提取單詞之間的關係，也不能生成更複雜的單詞含義。 \n",
    "\n",
    "為此，我們需要使用更複雜的處理庫，例如我們稍後會看到的 word2vec。\n",
    "\n",
    "<b>注意：</b> max features 參數中的一個小變化，現在它將保留 150 個總得分最高的標記。 \n",
    "\n",
    "這與最常見的略有不同，因為那些在 td-idf 計算中得分較低的詞將被丟棄。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (5572,)\n",
      "vectorized: (5572, 150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elsa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>all</th>\n",
       "      <th>already</th>\n",
       "      <th>am</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>won</th>\n",
       "      <th>work</th>\n",
       "      <th>www</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>ì_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564999</td>\n",
       "      <td>0.271367</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      about  after       all  already   am  amp   an       and  any       are  \\\n",
       "3816    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "2090    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "3510    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.610693   \n",
       "3539    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "2026    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "5007    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "1632    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.246175  0.0  0.000000   \n",
       "840     0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "5220    0.0    0.0  0.000000      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "4871    0.0    0.0  0.325929      0.0  0.0  0.0  0.0  0.000000  0.0  0.000000   \n",
       "\n",
       "      ...  will      with  won      work  www  yeah  yes       you      your  \\\n",
       "3816  ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000   \n",
       "2090  ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000   \n",
       "3510  ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.390351  0.000000   \n",
       "3539  ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.177867  0.000000   \n",
       "2026  ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000   \n",
       "5007  ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000   \n",
       "1632  ...   0.0  0.314699  0.0  0.000000  0.0   0.0  0.0  0.564999  0.271367   \n",
       "840   ...   0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000   \n",
       "5220  ...   0.0  0.483086  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000   \n",
       "4871  ...   0.0  0.000000  0.0  0.404161  0.0   0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "            ì_  \n",
       "3816  0.000000  \n",
       "2090  0.000000  \n",
       "3510  0.000000  \n",
       "3539  0.000000  \n",
       "2026  0.000000  \n",
       "5007  0.000000  \n",
       "1632  0.000000  \n",
       "840   0.000000  \n",
       "5220  0.000000  \n",
       "4871  0.404161  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF\n",
    "vec_tf = TfidfVectorizer(max_features=150)\n",
    "tmp = vec_tf.fit_transform(df[\"text\"])\n",
    "tok_cols = vec_tf.get_feature_names()\n",
    "tok_df = pd.DataFrame(tmp.toarray(), columns=tok_cols)\n",
    "print(\"original:\", df[\"text\"].shape)\n",
    "print(\"vectorized:\", tmp.shape)\n",
    "tok_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization Parameters\n",
    "\n",
    "There are several parameters that can be pretty important when doing vectorization:\n",
    "<ul>\n",
    "<li> Max Features - as seen above. Limits how many feature columns are produced. This will cap it to the N most frequent words instead of every word seen. \n",
    "<li> strip_accents - remove random characters such as accents. \n",
    "<li> lowercase - covert all to lower case. This is helpful as case matters in code, but doesn't matter for us. \n",
    "<li> stop_words - filter out stop words. More on this later. \n",
    "<li> tokenizer - we can specify our own tokenizer function, where we can layer in more processing. More on this later. \n",
    "<li> ngram_range - how \"big\" can tokens be? I.e. can you have a 2 word token - e.g. \"downhill skiing\". \n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 向量化參數\n",
    "\n",
    "在進行矢量化時，有幾個參數非常重要：\n",
    "<ul>\n",
    "<li> 最大功能 - 如上所示。 限制生成的特徵列的數量。 這會將其限制為 N 個最常見的單詞，而不是每個看到的單詞。\n",
    "<li> strip_accents - 刪除隨機字符，例如重音符號。\n",
    "<li> lowercase - 全部轉換為小寫。 這在代碼中區分大小寫時很有用，但對我們來說無關緊要。\n",
    "<li> stop_words - 過濾掉停用詞。 稍後會詳細介紹。\n",
    "<li> tokenizer - 我們可以指定我們自己的 tokenizer 函數，我們可以在其中進行更多處理。 稍後會詳細介紹。\n",
    "<li> ngram_range - 標記可以有多“大”？ IE。 你能有一個 2 字標記嗎？ “下坡滑雪”。\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Grams\n",
    "\n",
    "N-grams are a way to capture the relationship between words. For example, the phrase \"downhill skiing\" is a 2-gram, those two words together are a specific \"thing\", different from the words \"downhill\" and \"skiing\" by themselves. The N in n-grams is the number of words in the phrase that are stored as one token. Allowing n-grams that are longer than one word cam be extremely helpful in allowing our feature set to better capture the meaning of our text, it is common to have multi-word terms-of-art, product names, descriptions (e.g. \"dirty blonde\"), and so on. On the (potential) downside, it can increase the number of features dramatically, and can make the feature set more sparse. When allowing larger n-grams, particularly, it is common to limit the number of features up front and/or use some techniques later on to reduce the dimensionality of the feature set. A feature set that is 20 times wider than it is tall is probably not going to be ideal. \n",
    "\n",
    "![N-Gram Vectorization](images/ngram.png \"N-Gram Vectorization\" )\n",
    "\n",
    "##### N-Gram Vectorization\n",
    "\n",
    "We can allow longer n-grams with a hyperparameter, for this example I allowed things up to 3, we can see that the number of features will explode in size as now any up to n-word long sequence can be a feature in our feature set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N 元語法\n",
    "\n",
    "N-gram 是一種捕捉單詞之間關係的方法。 例如，短語“downhill skiing”是一個2-gram，\n",
    "\n",
    "這兩個詞加在一起是一個特定的“事物”，不同於單獨的“downhill”和“skiing”這兩個詞。 n-grams 中的 N 是短語中存儲為一個標記的單詞數。 \n",
    "\n",
    "允許長於一個詞的 n-grams 非常有助於讓我們的特徵集更好地捕捉文本的含義，通常有多個詞的技術術語、產品名稱、描述（例如“臟” 金發女郎”），等等。 \n",
    "\n",
    "在（潛在的）不利方面，它可以顯著增加特徵的數量，並可以使特徵集更加稀疏。 \n",
    "\n",
    "特別是當允許更大的 n-gram 時，通常會預先限制特徵的數量和/或稍後使用一些技術來降低特徵集的維數。 \n",
    "\n",
    "寬度是高度的 20 倍的特徵集可能並不理想。\n",
    "\n",
    "##### N-Gram 向量化\n",
    "\n",
    "我們可以允許帶有超參數的更長的 n-gram，在這個例子中我允許最多 3 個，我們可以看到特徵的數量將會爆炸式增長，\n",
    "\n",
    "因為現在任何長達 n 字的長序列都可以成為我們特徵中的一個特徵 放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (5572,)\n",
      "vectorized: (5572, 150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elsa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 in</th>\n",
       "      <th>00 in our</th>\n",
       "      <th>00 per</th>\n",
       "      <th>00 sub</th>\n",
       "      <th>00 sub 16</th>\n",
       "      <th>00 subs</th>\n",
       "      <th>00 subs 16</th>\n",
       "      <th>000</th>\n",
       "      <th>000 bonus</th>\n",
       "      <th>...</th>\n",
       "      <th>ûò is limping</th>\n",
       "      <th>ûò sound</th>\n",
       "      <th>ûò sound ok</th>\n",
       "      <th>ûò to</th>\n",
       "      <th>ûò to an</th>\n",
       "      <th>ûò very</th>\n",
       "      <th>ûò very entertaining</th>\n",
       "      <th>ûówell</th>\n",
       "      <th>ûówell done</th>\n",
       "      <th>ûówell done û_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 104564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  00 in  00 in our  00 per  00 sub  00 sub 16  00 subs  00 subs 16  \\\n",
       "2545  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "3466  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "1915  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "126   0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "1384  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "4862  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "3709  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "2161  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "743   0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "4760  0.0    0.0        0.0     0.0     0.0        0.0      0.0         0.0   \n",
       "\n",
       "      000  000 bonus  ...  ûò is limping  ûò sound  ûò sound ok  ûò to  \\\n",
       "2545  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "3466  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "1915  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "126   0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "1384  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "4862  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "3709  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "2161  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "743   0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "4760  0.0        0.0  ...            0.0       0.0          0.0    0.0   \n",
       "\n",
       "      ûò to an  ûò very  ûò very entertaining  ûówell  ûówell done  \\\n",
       "2545       0.0      0.0                   0.0     0.0          0.0   \n",
       "3466       0.0      0.0                   0.0     0.0          0.0   \n",
       "1915       0.0      0.0                   0.0     0.0          0.0   \n",
       "126        0.0      0.0                   0.0     0.0          0.0   \n",
       "1384       0.0      0.0                   0.0     0.0          0.0   \n",
       "4862       0.0      0.0                   0.0     0.0          0.0   \n",
       "3709       0.0      0.0                   0.0     0.0          0.0   \n",
       "2161       0.0      0.0                   0.0     0.0          0.0   \n",
       "743        0.0      0.0                   0.0     0.0          0.0   \n",
       "4760       0.0      0.0                   0.0     0.0          0.0   \n",
       "\n",
       "      ûówell done û_  \n",
       "2545             0.0  \n",
       "3466             0.0  \n",
       "1915             0.0  \n",
       "126              0.0  \n",
       "1384             0.0  \n",
       "4862             0.0  \n",
       "3709             0.0  \n",
       "2161             0.0  \n",
       "743              0.0  \n",
       "4760             0.0  \n",
       "\n",
       "[10 rows x 104564 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF\n",
    "vec_tf_ng = TfidfVectorizer(ngram_range=[1,3])\n",
    "tmp_ng = vec_tf_ng.fit_transform(df[\"text\"])\n",
    "tok_cols_ng = vec_tf_ng.get_feature_names()\n",
    "tok_df_ng = pd.DataFrame(tmp_ng.toarray(), columns=tok_cols_ng)\n",
    "print(\"original:\", df[\"text\"].shape)\n",
    "print(\"vectorized:\", tmp.shape)\n",
    "tok_df_ng.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model with Text\n",
    "\n",
    "We now have enough tools to use our text as a feature set, and train a predictive model. We can probably be a bit smarter with how we process our text, but for a first pass, we have something that works. Try running the code below with each vectorizer. \n",
    "\n",
    "Support vector machines are a good choice for text classification, as they are able to handle sparse feature sets without adaptation, and the model tends to deliver accurate predictions for this type of problem. The sparse feature set thing is a small concern for now, we'll look at ways to reduce the dimensionality of the feature set later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1188\n",
      "        spam       0.97      0.86      0.91       205\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.97      0.93      0.95      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svc = SVC()\n",
    "\n",
    "vec_cv = CountVectorizer(max_features=150, ngram_range=[1,2])\n",
    "\n",
    "y = df[\"target\"]\n",
    "X = df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipe1 = Pipeline([ \n",
    "                    (\"vect\", vec_cv),\n",
    "                    (\"model\", model_svc)\n",
    "])\n",
    "\n",
    "params = [\"vec_cv\"]\n",
    "\n",
    "pipe1.fit(X_train, y_train.ravel())\n",
    "preds = pipe1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "sns.heatmap(confusion_matrix(y_test, preds), annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Our predictions are pretty good!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Try with TD-IDF\n",
    "\n",
    "Try the previous prediction with the td-idf vectorizer. Play around with the ngrams if you have time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1209\n",
      "        spam       0.97      0.84      0.90       184\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.98      0.92      0.95      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svc = SVC()\n",
    "\n",
    "vec_tf = TfidfVectorizer(max_features=150)\n",
    "\n",
    "y = df[\"target\"]\n",
    "X = df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipe1 = Pipeline([ \n",
    "                    (\"vect\", vec_tf),\n",
    "                    (\"model\", model_svc)\n",
    "])\n",
    "\n",
    "params = [\"vec_cv\"]\n",
    "\n",
    "pipe1.fit(X_train, y_train.ravel())\n",
    "preds = pipe1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "sns.heatmap(confusion_matrix(y_test, preds), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Elaborate Language Processing\n",
    "\n",
    "In the example above we've done a \"base\" level of modelling - we transform the free text into something that we can process (the bag of words), and we can make predictions from it much like we would with any other one-hot encoded data. This process works fine, and it does deliver some pretty accurate results on our test data. \n",
    "\n",
    "To create NLP models that are more functional we can add some layers to our processing of the text to improve our understanding of the nuances of our text. Some things we can do are:\n",
    "<ul>\n",
    "<li> <b>Remove Stop Words</b> - common words like \"it\", \"a\", \"the\" are normally not all that useful in predicting the meaning, we can filter these out. \n",
    "<li> <b>Stemming</b> - coverting words down to their \"stem\". E.g. \"reasoning\" to \"reason\"\n",
    "<li> <b>Lemmatization</b> - similar to stemming, but tries to identify the correct stem contextually. E.g. \"Operating systems\" probably shouldn't become \"operate\" and \"system\"\n",
    "</ul>\n",
    "\n",
    "In general, stemming increases recall while harming precision. Lemmatization has similar impacts, but tends to be less aggressive, so the effects are smaller. The specific results are highly variable depending on the exact text that is used. Something that uses specific variations of words to mean specific things (e.g. science) is more likely to get no benefit or be negatively impacted - e.g. \"conditonally\" used in the context of a \"conditionally approved loan\" is probably not well represented by changing it to \"condition\". \n",
    "\n",
    "### NLTK Library\n",
    "\n",
    "NLTK is a library that provides a bunch of language processing stuff that we can use such as stop words and tokenizers. We'll leverage it here to make custom tokenizers to incorporate some of those features above. The things we are downloading here are pre-made sets of data, like stop words, and pretrained lists of \"root words\" that we can use to break words down into their root format. \n",
    "\n",
    "<b>Note:</b> the \"for package\" part there downloads the wordsets to your computer. NLTK has these prebuilt libraries of data that allow for the functions to do the stop words, stemming, and lemmatization. It might take a minute the first time you run it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更精細的語言處理\n",
    "\n",
    "在上面的示例中，我們已經完成了“基礎”級別的建模——我們將自由文本轉換為我們可以處理的東西（詞袋），\n",
    "\n",
    "並且我們可以從中做出預測，就像我們對其他任何東西所做的一樣—— 熱編碼數據。 \n",
    "\n",
    "這個過程運行良好，它確實為我們的測試數據提供了一些非常準確的結果。\n",
    "\n",
    "為了創建功能更強大的 NLP 模型，我們可以在文本處理中添加一些層，以提高我們對文本細微差別的理解。 我們可以做的一些事情是：\n",
    "<ul>\n",
    "<li> <b>刪除停用詞</b> - 像“it”、“a”、“the”這樣的常用詞通常在預測含義方面並不是那麼有用，我們可以過濾掉它們。\n",
    "<li> <b>詞幹提取</b> - 將單詞隱藏到它們的“詞幹”。 例如。 “推理”到“推理”\n",
    "<li> <b>詞形還原</b> - 類似於詞幹提取，但嘗試根據上下文識別正確的詞幹。 例如。 “操作系統”可能不應該變成“操作”和“系統”\n",
    "</ul>\n",
    "\n",
    "一般來說，詞幹提取會增加召回率，同時會損害準確率。 詞形還原具有類似的影響，但往往不那麼激進，因此影響較小。 \n",
    "\n",
    "根據所使用的確切文本，具體結果變化很大。 使用特定單詞變體來表示特定事物（例如科學）的事物更有可能得不到任何好處或受到負面影響 - \n",
    "\n",
    "例如 在“有條件批准的貸款”的上下文中使用的“有條件地”可能無法通過將其更改為“條件”來很好地表示。\n",
    "\n",
    "### NLTK 庫\n",
    "\n",
    "NLTK 是一個庫，它提供了一堆我們可以使用的語言處理工具，例如停用詞和分詞器。 \n",
    "\n",
    "我們將在這裡利用它來製作自定義分詞器，以合併上面的一些功能。 \n",
    "\n",
    "我們在這裡下載的是預製的數據集，如停用詞和預訓練的“詞根”列表，我們可以使用它們將詞分解為它們的詞根格式。\n",
    "\n",
    "<b>注意：</b> 此處的“for package”部分將單詞集下載到您的計算機。 \n",
    "\n",
    "NLTK 具有這些預構建的數據庫，允許函數執行停用詞、詞幹提取和詞形還原。 第一次運行它可能需要一分鐘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Elsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Elsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Elsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "for package in ['stopwords','punkt','wordnet']:\n",
    "    nltk.download(package)\n",
    "    \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Tokenizers\n",
    "\n",
    "The vecorization libraries in sklearn allow you do specify the function to use to do tokenization. We can use this to include other processing that we'd like as part of the process, such as removing stop words or stemming. The tokenizer functions below can, potentially, contain anything you'd like. As long as the call function returns a list of tokens, it should work. \n",
    "\n",
    "<b>Note:</b> if you look up examples, these functions will often be written into one lines, I broke them out so they're hopefully easier to read. They would also likely be much faster if we were to vectorize the code instead of using loops, but again, this is easy to read. \n",
    "\n",
    "#### Stop! In the Name of Words. Before you Break my Model.\n",
    "\n",
    "First, we will try to make a stop word tokenizer. If something is a stop word, we shall leave it out. As noted above, we can build this into the vectorizer, so why do it? This will allow for customizing the stopwords used - some applications may have a different usage of words, so changing stopwords makes sense. It is also a super fun exercise! \n",
    "\n",
    "This is also the most simple example we can try :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定制分詞器\n",
    "\n",
    "sklearn 中的矢量化庫允許您指定用於進行標記化的函數。 我們可以使用它來包括我們希望作為流程一部分的其他處理，例如刪除停用詞或詞幹提取。 \n",
    "\n",
    "下面的分詞器函數可能包含您想要的任何內容。 只要調用函數返回標記列表，它就應該可以工作。\n",
    "\n",
    "<b>注意：</b>如果您查找示例，這些函數通常會被寫成一行，我將它們分開，希望它們更容易閱讀。 \n",
    "\n",
    "如果我們將代碼向量化而不是使用循環，它們也可能會快得多，但同樣，這很容易閱讀。\n",
    "\n",
    "＃＃＃＃ 停止！ 以文字之名。 在你破壞我的模型之前。\n",
    "\n",
    "首先，我們將嘗試製作一個停用詞分詞器。 如果某個東西是停用詞，我們將把它去掉。 \n",
    "\n",
    "如上所述，我們可以將其構建到矢量化器中，那麼為什麼要這樣做呢？ \n",
    "\n",
    "這將允許自定義使用的停用詞 - 某些應用程序可能有不同的單詞用法，因此更改停用詞是有意義的。 這也是一項超級有趣的運動！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swTokenizer(object):\n",
    "    def __init__(self, stop_words):\n",
    "        self.stop_words = stop_words\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        filtered_tok = []\n",
    "        for tok in tokens:\n",
    "            if tok not in stop_words:\n",
    "                filtered_tok.append(tok)\n",
    "        return filtered_tok"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "\n",
    "Stemming and lemmatization are similar - they both aim to break words down to their \"root\". For example, the word \"shoes\" probably has the same meaning as the word \"shoe\" for our purposes. Each approaches this in a slightly different way, and to understand that we need to take a look at the conecpt of similarity, which we'll look at more next time. \n",
    "\n",
    "#### Similarity\n",
    "\n",
    "When processing text, we can think of things being similar in two different ways - similar text or similar meaning - or lexical and semantic similarity. Things that are lexically similar use similar words, things that are semantically similar have similar meanings, even if the words are different. The stemming techniques here aren't explicit comparisons of those similarity types, but they follow the same concepts. Stemming breaks words down to their lexical root, lemmatization tries to find the semantic root.\n",
    "\n",
    "#### Stemming\n",
    "\n",
    "Stemming is the most simple, it just removes common prefixes and suffixes to extract the root of the word. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 詞乾化和詞形還原\n",
    "\n",
    "詞幹提取和詞形還原相似——它們都旨在將單詞分解為它們的“詞根”。 例如，對於我們的目的，“shoes”這個詞可能與“shoe”這個詞具有相同的含義。 \n",
    "\n",
    "每個人都以略有不同的方式來處理這個問題，要理解我們需要看一下相似性的概念，我們下次會詳細介紹。\n",
    "\n",
    "####相似度\n",
    "\n",
    "在處理文本時，我們可以通過兩種不同的方式來思考事物的相似性——相似的文本或相似的含義——或者詞彙和語義的相似性。 \n",
    "\n",
    "詞彙相似的事物使用相似的詞，語義相似的事物具有相似的含義，即使這些詞不同。 \n",
    "\n",
    "這裡的詞幹提取技術並不是對這些相似類型的明確比較，但它們遵循相同的概念。 詞乾化將單詞分解為詞根，詞形還原試圖找到語義根。\n",
    "\n",
    "#### 詞幹提取\n",
    "\n",
    "Stemming 是最簡單的，它只是去除常見的前綴和後綴來提取單詞的詞根。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stemTokenizer(object):\n",
    "    def __init__(self, stop_words):\n",
    "        self.stop_words = stop_words\n",
    "        from nltk.stem import SnowballStemmer\n",
    "        self.stemmer = SnowballStemmer(language='english')\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        filtered_tok = []\n",
    "        for tok in tokens:\n",
    "            if tok not in stop_words:\n",
    "                filtered_tok.append(self.stemmer.stem(tok))\n",
    "        return filtered_tok"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "\n",
    "Lemmatization is slightly more sophisticated, it attempts to find the semantic root, called the lemma, of a word using a search of a dictionary (we provide one from NLTK). For example, the lemma of \"better\" is \"good\". This is a \"smarter\" approach that the more simple stemming function above, but it is also more complex and slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lemmaTokenizer(object):\n",
    "    def __init__(self, stop_words):\n",
    "        self.stop_words = stop_words\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        filtered_tok = []\n",
    "        for tok in tokens:\n",
    "            if tok not in stop_words:\n",
    "                filtered_tok.append(self.lemmatizer.lemmatize(tok))\n",
    "        return filtered_tok"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with More Processing and Grid Search\n",
    "\n",
    "We can try to see which processing setup works best, the winner will depend on how the text is written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vect',\n",
      "                 TfidfVectorizer(max_features=1500, norm='l1',\n",
      "                                 tokenizer=<__main__.stemTokenizer object at 0x00000265C6EE04F0>)),\n",
      "                ('model', SVC())])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1189\n",
      "        spam       1.00      0.88      0.93       204\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.99      0.94      0.96      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec_tf = TfidfVectorizer()\n",
    "\n",
    "y = df[\"target\"]\n",
    "X = df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipe2 = Pipeline([ \n",
    "                    #(\"vect\", vec_cv),\n",
    "                    (\"vect\", vec_tf),\n",
    "                    (\"model\", model_svc)\n",
    "])\n",
    "\n",
    "params = {\"vect__max_features\":[100,500,1000,1500],\n",
    "            \"vect__tokenizer\":(swTokenizer(stop_words), stemTokenizer(stop_words), lemmaTokenizer(stop_words) ),\n",
    "            \"vect__norm\":[\"l1\",\"l2\"]\n",
    "            }\n",
    "\n",
    "grid = GridSearchCV(estimator  = pipe2, \n",
    "                               param_grid = params, \n",
    "                               scoring    = \"balanced_accuracy\",\n",
    "                               cv         = 5,\n",
    "                               n_jobs     =-1)\n",
    "\n",
    "grid.fit(X_train, y_train.ravel())\n",
    "best = grid.best_estimator_\n",
    "preds = best.predict(X_test)\n",
    "print(best)\n",
    "print(classification_report(y_test, preds))\n",
    "sns.heatmap(confusion_matrix(y_test, preds), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "\n",
    "We are accurate! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Categorize the following newsgroups. The data are posts from different newgroup boards. Try to categorize the data in either the atheism or religion groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "remove = (\"headers\", \"footers\", \"quotes\")\n",
    "categories = [\"alt.atheism\", \"talk.religion.misc\"]\n",
    "\n",
    "data_train = fetch_20newsgroups(\n",
    "    subset=\"train\", categories=categories, shuffle=True, random_state=42, remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(\n",
    "    subset=\"test\", categories=categories, shuffle=True, random_state=42, remove=remove)\n",
    "\n",
    "X_train3 = data_train.data\n",
    "y_train3 = data_train.target\n",
    "X_test3 = data_test.data\n",
    "y_test3 = data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vect',\n",
      "                 TfidfVectorizer(max_features=2500,\n",
      "                                 tokenizer=<__main__.lemmaTokenizer object at 0x00000265C79BF070>)),\n",
      "                ('model', SVC())])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72       319\n",
      "           1       0.65      0.47      0.55       251\n",
      "\n",
      "    accuracy                           0.66       570\n",
      "   macro avg       0.66      0.64      0.64       570\n",
      "weighted avg       0.66      0.66      0.65       570\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec_tf3 = TfidfVectorizer()\n",
    "model_svc3 = SVC()\n",
    "\n",
    "pipe3 = Pipeline([ \n",
    "                    (\"vect\", vec_tf3),\n",
    "                    (\"model\", model_svc3)\n",
    "])\n",
    "\n",
    "params3 = {\"vect__max_features\":[100,500,1000,1500,2000,2500],\n",
    "            \"vect__tokenizer\":(swTokenizer(stop_words), stemTokenizer(stop_words), lemmaTokenizer(stop_words) ),\n",
    "            \"vect__norm\":[\"l1\",\"l2\"]\n",
    "            }\n",
    "\n",
    "grid3 = GridSearchCV(estimator  = pipe3, \n",
    "                               param_grid = params3, \n",
    "                               scoring    = \"balanced_accuracy\",\n",
    "                               cv         = 5,\n",
    "                               n_jobs     =-1)\n",
    "\n",
    "grid3.fit(X_train3, y_train3)\n",
    "best3 = grid3.best_estimator_\n",
    "preds3 = best3.predict(X_test3)\n",
    "print(best3)\n",
    "print(classification_report(y_test3, preds3))\n",
    "sns.heatmap(confusion_matrix(y_test3, preds3), annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40846f95e88ae24f681f7d79d7396bca459ce37b2ecada686cfbc3bbe9daaf0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
